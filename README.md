# A Multimodal Deep Learning Model for the Classification of Breast Cancer Subtypes


## ğŸ“ Overview

This repository contains the code supporting our research paper on **Breast Cancer Subtyping**. Our deep learning model integrates mammography images with clinical metadata to classify breast lesions into five categories: benign, Luminal A, Luminal B, HER2-enriched, and Triple-negative.

ğŸ”¬ **Key Highlights:**
- Enhancing breast cancer subtype classification by integrating mammography images with clinical metadata.
- Utilizing public breast cancer dataset for reproducibility.
- comparative analysis between unimodal (images only) and hybrid models revealed the substantial benefits of integrating clinical metadata.

## ğŸ“„ Paper
If you use this work, please cite our paper:

> **Title:** A Multimodal Deep Learning Model for the Classification of Breast Cancer Subtypes

> **Authors:** Chaima Ben Rabah, Aamenah Sattar, Ahmed Ibrahim, and Ahmed Serag

> **Journal:** [Link to Paper](https://www.mdpi.com/2075-4418/15/8/995)

> **Bibtex:**
```
@article{ben2025multimodal,
  title={A Multimodal Deep Learning Model for the Classification of Breast Cancer Subtypes},
  author={Ben Rabah, Chaima and Sattar, Aamenah and Ibrahim, Ahmed and Serag, Ahmed},
  journal={Diagnostics},
  volume={15},
  number={8},
  pages={995},
  year={2025},
  publisher={MDPI}
}
```

## ğŸ“‚ Repository Structure
```
â”œâ”€â”€ notebooks/          # Jupyter notebooks for analysis
â”œâ”€â”€ requirements.txt    # Required dependencies
â”œâ”€â”€ README.md           # Project documentation
```

## ğŸš€ Important

We used the CMMD dataset, a collection of breast mammography images and the corresponding clinical data for the subjects. Both images and data are publicly available in The Cancer Imaging Archive (TCIA) at [Link to dataset](https://www.cancerimagingarchive.net/).

## ğŸ¤ Contributing
We welcome contributions! Feel free to submit a pull request or open an issue.


---

ğŸŒŸ **If you find this repository useful, please consider starring â­ it to support our work!**

