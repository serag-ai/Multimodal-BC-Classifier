{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "soVY2IJk-t2i"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pb6GI-Kkz9V"
   },
   "outputs": [],
   "source": [
    "# Load the images from the .npy file\n",
    "files_path = '/data/'   #put the correct path\n",
    "X_train_images = np.load(files_path+'/X_train_images.npy')\n",
    "X_val_images = np.load(files_path+'/X_val_images.npy')\n",
    "X_test_images = np.load(files_path+'/X_test_images.npy')\n",
    "\n",
    "y_train = np.load(files_path+'/y_train.npy')\n",
    "y_val = np.load(files_path+'/y_val.npy')\n",
    "y_test = np.load(files_path+'/y_test.npy')\n",
    "\n",
    "# Check the shapes\n",
    "print(\"Shape of the train images array:\", X_train_images.shape)\n",
    "print(\"Shape of the val images array:\", X_val_images.shape)\n",
    "print(\"Shape of the test images array:\", X_test_images.shape)\n",
    "\n",
    "print(\"Shape of the train labels array:\", y_train.shape)\n",
    "print(\"Shape of the val labels array:\", y_val.shape)\n",
    "print(\"Shape of the test labels array:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "subtypes = [\"Benign\",\"HER2\",\"LumA\",\"LumB\",\"TN\"]\n",
    "\n",
    "# Count the number of images per class\n",
    "unique_classes, counts = np.unique(np.argmax(y_train,axis=1), return_counts=True)\n",
    "\n",
    "# Create a DataFrame for seaborn\n",
    "df = pd.DataFrame({'Class': unique_classes, 'Count': counts})\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Class', y='Count', data=df, palette='viridis')\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Number of Images', fontsize=12)\n",
    "plt.title('Distribution of Images by Class', fontsize=16)\n",
    "plt.xticks(range(0,num_classes),subtypes)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImXHJpNwkz9W"
   },
   "outputs": [],
   "source": [
    "def create_fusion_model(num_classes=5):\n",
    "    # Image input branch\n",
    "    image_input = tf.keras.Input(shape=(224, 224, 3))\n",
    "    base_model = Xception(weights='imagenet', include_top=False, input_tensor=image_input)\n",
    "\n",
    "    # Freeze early layers\n",
    "    for layer in base_model.layers[:-20]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Combine branches\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=image_input, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Fh282YC68kw"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Create and compile model\n",
    "    model = create_fusion_model()\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.AUC(name=\"AUC\"),]\n",
    "    )\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(np.argmax(y_train, axis=1)),\n",
    "        y=np.argmax(y_train, axis=1)\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_images,\n",
    "        y_train,\n",
    "        validation_data=(X_val_images, y_val),\n",
    "        epochs= 10,\n",
    "        batch_size=64,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_loss, val_acc, val_auc = model.evaluate(\n",
    "        X_val_images,\n",
    "        y_val,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"\\nValidation Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7jZVWDL68iX",
    "outputId": "bc70c32b-6f67-4562-d9a6-0f625f8a1292"
   },
   "outputs": [],
   "source": [
    "model, history = main()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Plot AUC figure\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['AUC'])\n",
    "plt.plot(history.history['val_AUC'])\n",
    "plt.title('model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_images, verbose=0)\n",
    "\n",
    "test_loss, test_acc, test_auc = model.evaluate(\n",
    "        X_test_images,\n",
    "        y_test,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "print(f\"\\nTest AUC: {test_auc:.4f}\")\n",
    "\n",
    "predictions = y_pred\n",
    "truth = y_test\n",
    "target_names = subtypes\n",
    "\n",
    "print(classification_report(np.argmax(truth, axis=1), np.argmax(predictions,axis=1), target_names=target_names))\n",
    "print('*****************')\n",
    "\n",
    "res = []\n",
    "for l in [0,1,2,3,4]:\n",
    "    prec,recall,_,_ = precision_recall_fscore_support(np.array(np.argmax(truth, axis=1))==l,\n",
    "                                                      np.array(np.argmax(predictions,axis=1))==l,\n",
    "                                                      pos_label=True,average=None)\n",
    "    res.append([target_names[l],recall[0],recall[1]])\n",
    "aa = pd.DataFrame(res,columns = ['class','sensitivity','specificity'])\n",
    "\n",
    "print(aa)\n",
    "print('*****************')\n",
    "\n",
    "\n",
    "\n",
    "# Create confusion matrix\n",
    "cmtx = confusion_matrix(np.argmax(truth, axis=1), np.argmax(predictions,axis=1))\n",
    "print(cmtx)\n",
    "\n",
    "def plot_conf(cm, label : str = \"\", figsize=(7,4)) :\n",
    "    fig, ax = plt.subplots(figsize=figsize)         # Sample figsize in inches\n",
    "    ax = sns.heatmap(cmtx, annot=True, linewidths=.5, ax=ax, cmap='Blues')\n",
    "    ax.set_title('Confusion Matrix with labels\\n\\n');\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ');\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels(target_names)\n",
    "    ax.yaxis.set_ticklabels(target_names)\n",
    "    \n",
    "plot_conf(cmtx,target_names)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(truth.ravel(), predictions.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(truth[:, i], predictions[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "# Interpolate all ROC curves at these points\n",
    "mean_tpr = np.zeros_like(fpr_grid)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    mean_tpr += np.interp(fpr_grid, fpr[i], tpr[i])  # linear interpolation\n",
    "\n",
    "# Average it and compute AUC\n",
    "mean_tpr /= num_classes\n",
    "\n",
    "fpr[\"macro\"] = fpr_grid\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\",\"red\",\"green\",\"yellow\"])\n",
    "for class_id, color in zip(range(num_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        truth[:, class_id],\n",
    "        predictions[:, class_id],\n",
    "        name=f\"ROC curve for {target_names[class_id]}\",\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(class_id == 2),\n",
    "    )\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"Extension of Receiver Operating Characteristic\\nto One-vs-Rest multiclass\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take subset of 20 images per class\n",
    "samples_per_class = 20\n",
    "\n",
    "# Initialize lists to store selected indices, images, and labels\n",
    "selected_indices = []\n",
    "new_images = []\n",
    "new_labels = []\n",
    "\n",
    "y_test_enc = np.argmax(y_test,axis=1)\n",
    "\n",
    "# Iterate through each class\n",
    "for class_label in range(5):  # Classes 0 to 4\n",
    "    # Get indices of samples belonging to the current class\n",
    "    class_indices = np.where(y_test_enc == class_label)[0]\n",
    "    \n",
    "    # Randomly select 15 indices from the current class\n",
    "    if len(class_indices) >= samples_per_class:\n",
    "        selected_class_indices = np.random.choice(class_indices, samples_per_class, replace=False)\n",
    "    else:\n",
    "        print(f\"Warning: Class {class_label} has fewer than {samples_per_class} samples. Using all available samples.\")\n",
    "        selected_class_indices = class_indices\n",
    "    \n",
    "    # Add selected indices to the list\n",
    "    selected_indices.extend(selected_class_indices)\n",
    "\n",
    "# Extract the corresponding images, metadata, and labels\n",
    "new_images = X_test_images[selected_indices]\n",
    "new_labels = y_test_enc[selected_indices]\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"New images shape:\", new_images.shape)\n",
    "print(\"New labels shape:\", new_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the last layer of the model is \"dense_3\" \n",
    "last_conv_layer = model.get_layer(\"dense_3\")\n",
    "features_extractor = tf.keras.Model(inputs= model.input, outputs=last_conv_layer.output)\n",
    "\n",
    "features = features_extractor(new_images) \n",
    "\n",
    "# Perform t-SNE dimensionality reduction\n",
    "tsne = TSNE(n_components=2, perplexity=50).fit_transform(features)\n",
    "\n",
    "def scale_to_01_range(x):\n",
    "    value_range = (np.max(x) - np.min(x))\n",
    "    starts_from_zero = x - np.min(x)\n",
    "    return starts_from_zero / value_range\n",
    "\n",
    "\n",
    "# Extract x and y coordinates\n",
    "tx = tsne[:, 0]\n",
    "ty = tsne[:, 1]\n",
    "\n",
    "tx = scale_to_01_range(tx)\n",
    "ty = scale_to_01_range(ty)\n",
    "\n",
    "# Assuming lbls is a list or array containing class labels\n",
    "unique_labels = np.unique(new_labels)  # Get unique class labels\n",
    "\n",
    "# Define a colormap or color dictionary (optional)\n",
    "\n",
    "colors_dict = {label: color for label, color in zip(unique_labels, [\"red\", \"green\", \"blue\", \"purple\",\"orange\"])}\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)  \n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    # Find indices for current class\n",
    "    indices = [i for i, l in enumerate(new_labels) if l == label]\n",
    "    print(indices)\n",
    "    # Extract coordinates and color based on label\n",
    "    current_tx = np.take(tx, indices)\n",
    "    current_ty = np.take(ty, indices)\n",
    "    if isinstance(colors_dict, dict):\n",
    "        color = colors_dict[label]\n",
    "    else:\n",
    "        color = cmap(i / len(unique_labels))  # Color based on colormap\n",
    "\n",
    "    # Add scatter plot\n",
    "    ll = target_names[label]\n",
    "    ax.scatter(current_tx, current_ty, c=color, marker='.',label=ll)\n",
    "\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end! "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
